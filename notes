
db record format:
. md5sum -- for both:
.. filename
.. uniqueness
. label name 
. coordinates
. date/time
. width/height
. user name

import steps:
1) prompt for label name for
imported files (ie, '2015 vacation')

2) read files
. md5sum compare against DB entries
 ( and file system ?? ) 
. if unique:
.. copy file with md5sum name
into directory... 
.... if copy successful:

3) put as much of above info as possible
into db
... if you can't read any of it, store only
	the file name (md5sum)
... if db entry NOT successful:
..... delete file


--------------
keeping map and list in sync:
. not every item in list has pin
. every pin has an item in list

when list item clicked:
. set pin center of map
.. animate?
. change zoom level ?
.. not currently
. change pin color
. change list item color

when pin clicked
. change pin color
. change list item color

--------------------
client-side workflow:
. initialize map
. get photo json from server
. for each json entry:
	add item (a tag) to list on left
	add item to photoArray (for photoSwipe -- this
	 could actually just be the json itself, if not for
	 photoSwipe requiring 'h', 'w', and 'src' tags 
	 specifically )
. add photoSwipe click handlers to items in list
. add pins to map
. add additional listeners to items in list, but these
are done by delegating through a tags' parent div, not
on individual items:
	center on map Pin
	change color of viewed Pins


-----------------
import country geojson
### first have to strip off "featureCollection" tag, then wrap entire file in array brackets:
mongoimport --drop --db photo_mapper --collection countries --type json --file countries.geojson --jsonArray
# find in Mongo client:
var italy = db.countries.findOne({'properties.admin': 'Italy'})


# scratch:
var monk = require('monk');

var db = monk('localhost:27017/photo_mapper');
var photoCol = db.get('photo_mapper');
var countryCol = db.get('countries');
var photos = [];
var countries = [];

// temporary var to hold photo data converted
// to geojson, ultimately I need to make the photo 
// records themselves hold this data:
photoCol.find({}, function(e,docs){
	docs.forEach(function(i) { 
		console.log(i);
		if (i.longitude && i.latitude) {
			photos.push(
				geometry: {
					"type": "Point",
					"coordinates": [
						i.longitude,  
						i.latitude 
					]}
			); 
		}
	});
});

// same as above but put it into separate
// collection instead of variable:
var pointCol = db.get('points')
var photos = [];
photoCol.find({}, function(e,docs){
	photos = docs;
});
photos.forEach(function(i) {
	if (i.longitude && i.latitude) {
		pointCol.insert(
		{
			geometry: { 
				"type": "Point",
				"coordinates": [
					i.longitude,
					i.latitude
				]
			}
		},
		function(err, docs) {
			if (err) throw err;
		});
	}
});


// find italy and assign to var:
var italy; 
countryCol.findOne({'properties.admin': 'Italy'}).on('success', function(doc) { italy = doc; });


// now see if it can find photos within Italy:
pointCol.find(
	{
		geometry: { 
			$geoWithin: { 
				$geometry: italy.geometry
			}
		}
	},
	function(err, docs) {
		docs.forEach(function(curr) {
			console.log(curr);
		});
	}
);

var point = {
  "type": "Point",
  "coordinates": [
    longitude,  
    latitude 
  ]
};

// iterate through countries, find photos that fall within
// them:
// Antarctica, Russia, and Fiji throw errors:
var countries;
countryCol.find({}).on('success', function(doc) { countries = doc; });
countries.forEach(function(country) {
	photoCol.find(
		{
			geojson: {
				$geoWithin: {
					$geometry: country.geometry
				}
			}
		},
		function(err, docs) {
			if (err) console.log(country.properties.admin,' error: ',err);
			if (docs) {
				docs.forEach(function(curr) {
					console.log(curr);
				});
			}
		}
	);
});
------------------------
steps for adding country data:
. test 

quality=30 -- total size 218M
full quality -- total size 441M


--------------------------
plotting /clustering notes:

from pymongo import MongoClient
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.cluster.vq import kmeans, kmeans2, whiten
from sklearn.cluster import DBSCAN

MONGODB_HOST = '192.168.1.69'
MONGODB_PORT = 27017
DB_NAME = 'photo_mapper'
COLLECTION_NAME='photo_mapper'
connection = MongoClient(MONGODB_HOST, MONGODB_PORT)
collection = connection[DB_NAME][COLLECTION_NAME]

raw_results = [ i for i in collection.find() ]
results = 	[ i['geojson']['coordinates'] 
				for i in collection.find() 
				# compound if sucks, maybe better way to get truth of all elements in array:
				if i['geojson']['coordinates'][0] 
				and i['geojson']['coordinates'][1] 
			]

# save scatter plot of coordinates plotted on graph:
df = pd.DataFrame(results)
df.columns = ['longitude','latitude']
df.plot.scatter('longitude', 'latitude')
#plt.savefig('/tmp/out.png')

#http://geoffboeing.com/2014/08/clustering-to-reduce-spatial-data-set-size/
coordinates = df.as_matrix(columns=['longitude', 'latitude'])
N = len(coordinates)
k = 20
i = 50
w = whiten(coordinates)
cluster_centroids, closest_centroids = kmeans2(w, k, iter=i, minit='points')

plt.figure(figsize=(10, 6), dpi=100)
plt.scatter(cluster_centroids[:,0], cluster_centroids[:,1], c='r', alpha=.7, s=150)
plt.scatter(w[:,0], w[:,1], c='k', alpha=.3, s=10)
plt.show()

rs = pd.DataFrame(df)
rs['closest_centroid'] = closest_centroids
rs.drop_duplicates(subset=['closest_centroid'], take_last=False, inplace=True)
rs.head()


plt.figure(figsize=(10, 6), dpi=100)
rs_scatter = plt.scatter(rs['longitude'], rs['latitude'], c='r', alpha=.7, s=150)
df_scatter = plt.scatter(df['longitude'], df['latitude'], c='k', alpha=.3, s=5)
plt.title('Full data set vs k-means reduced set')
plt.legend((df_scatter, rs_scatter), ('Full set', 'Reduced set'), loc='upper left')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()


#df = pd.DataFrame(results)
#df.columns = ['longitude','latitude']
#coordinates = df.as_matrix(columns=['longitude', 'latitude'])
def dbscan_stuff(coordinates):
	""" take coordinate dataframe, print number of 
		clusters -- http://geoffboeing.com/2014/08/
					clustering-to-reduce-spatial-data-set-size/ """
	db = DBSCAN(eps=.01, min_samples=1).fit(coordinates)
	labels = db.labels_
	num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
	clusters = pd.Series([coordinates[labels == i] for i in xrange(num_clusters)])
	print('Number of clusters: %d' % num_clusters)

dbscan_stuff(coordinates)


###############################################################
file uploads
. files get uploaded to endpoint /api/users/<user>/albums/<album>/photos 
. server:
	-- save files to UPLOAD_DIR/TEMPDIR (python module tempdir for TEMPDIR)
	-- process files -- use existing import_data code
		-- put json in db
 		-- send to s3
	-- delete tempdir


